{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray[rllib] tensorflow\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\sviluppo\\anaconda\\lib\\site-packages (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability==0.19.0\n",
      "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
      "     ---------------------------------------- 6.7/6.7 MB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gast>=0.3.2 in d:\\sviluppo\\anaconda\\lib\\site-packages (from tensorflow-probability==0.19.0) (0.4.0)\n",
      "Requirement already satisfied: decorator in d:\\sviluppo\\anaconda\\lib\\site-packages (from tensorflow-probability==0.19.0) (5.1.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\sviluppo\\anaconda\\lib\\site-packages (from tensorflow-probability==0.19.0) (1.24.2)\n",
      "Requirement already satisfied: absl-py in d:\\sviluppo\\anaconda\\lib\\site-packages (from tensorflow-probability==0.19.0) (1.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in d:\\sviluppo\\anaconda\\lib\\site-packages (from tensorflow-probability==0.19.0) (2.0.0)\n",
      "Requirement already satisfied: six>=1.10.0 in d:\\sviluppo\\anaconda\\lib\\site-packages (from tensorflow-probability==0.19.0) (1.16.0)\n",
      "Requirement already satisfied: dm-tree in d:\\sviluppo\\anaconda\\lib\\site-packages (from tensorflow-probability==0.19.0) (0.1.8)\n",
      "Installing collected packages: tensorflow-probability\n",
      "Successfully installed tensorflow-probability-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-probability==0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gymnasium as gym\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "#import ray\n",
    "from ray.air import Checkpoint\n",
    "from ray.air.config import RunConfig\n",
    "from ray.train.rl.rl_predictor import RLPredictor\n",
    "from ray.train.rl.rl_trainer import RLTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.air.result import Result\n",
    "from ray.rllib.algorithms.bc import BC\n",
    "from ray.tune.tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rl_ppo_online(num_workers: int, use_gpu: bool = False) -> Result:\n",
    "    print(\"Starting online training\")\n",
    "    trainer = RLTrainer(\n",
    "        run_config=RunConfig(stop={\"training_iteration\": 5}),\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        algorithm=\"PPO\",\n",
    "        config={\n",
    "            \"env\": \"CartPole-v1\",\n",
    "            \"framework\": \"tf\",\n",
    "        },\n",
    "    )\n",
    "    # Todo (krfricke/xwjiang): Enable checkpoint config in RunConfig\n",
    "    # result = trainer.fit()\n",
    "    tuner = Tuner(\n",
    "        trainer,\n",
    "        _tuner_kwargs={\"checkpoint_at_end\": True},\n",
    "    )\n",
    "    result = tuner.fit()[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_checkpoint(checkpoint: Checkpoint, num_episodes) -> list:\n",
    "    predictor = RLPredictor.from_checkpoint(checkpoint)\n",
    "\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        reward = 0.0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = predictor.predict(np.array([obs]))\n",
    "            obs, r, done, _ = env.step(action[0])\n",
    "            reward += r\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting online training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 16:33:19,992\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-02-28 16:34:16</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:52.57        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.4/15.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/4.01 GiB heap, 0.0/2.01 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>AIRPPO_3cf6c_00000</td><td>TERMINATED</td><td>127.0.0.1:23572</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         27.5592</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">  128.79</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">            128.79</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 16:33:24,143\tINFO algorithm_config.py:2899 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2023-02-28 16:33:24,179\tINFO algorithm_config.py:2899 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(AIRPPO pid=23572)\u001b[0m 2023-02-28 16:33:32,526\tWARNING algorithm_config.py:596 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(AIRPPO pid=23572)\u001b[0m 2023-02-28 16:33:32,526\tINFO algorithm_config.py:2899 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(AIRPPO pid=23572)\u001b[0m 2023-02-28 16:33:32,819\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18384)\u001b[0m D:\\Sviluppo\\anaconda\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18384)\u001b[0m   if not isinstance(terminated, (bool, np.bool8)):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=12392)\u001b[0m 2023-02-28 16:33:42,989\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=12392)\u001b[0m D:\\Sviluppo\\anaconda\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=12392)\u001b[0m   if not isinstance(terminated, (bool, np.bool8)):\n",
      "\u001b[2m\u001b[36m(AIRPPO pid=23572)\u001b[0m 2023-02-28 16:33:48,690\tINFO trainable.py:172 -- Trainable.setup took 15.873 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(AIRPPO pid=23572)\u001b[0m 2023-02-28 16:33:48,691\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics                                                                                                                                              </th><th>counters                                                                                                                            </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname       </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                           </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                      </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                 </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>AIRPPO_3cf6c_00000</td><td style=\"text-align: right;\">                  20000</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.009012222290039062, &#x27;StateBufferConnector_ms&#x27;: 0.010036945343017578, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.12197756767272949}</td><td>{&#x27;num_env_steps_sampled&#x27;: 20000, &#x27;num_env_steps_trained&#x27;: 20000, &#x27;num_agent_steps_sampled&#x27;: 20000, &#x27;num_agent_steps_trained&#x27;: 20000}</td><td>{}              </td><td>2023-02-28_16-34-16</td><td>True  </td><td style=\"text-align: right;\">            128.79</td><td>{}             </td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">               128.79</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">             346</td><td>fdb77e61f1684ee0b76397ace8c72295</td><td>LAPTOP-P1JP2TCI</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.30000001192092896, &#x27;cur_lr&#x27;: 4.999999873689376e-05, &#x27;total_loss&#x27;: 9.772552, &#x27;policy_loss&#x27;: -0.019828321, &#x27;vf_loss&#x27;: 9.791359, &#x27;vf_explained_var&#x27;: -0.013446819, &#x27;kl&#x27;: 0.0033996392, &#x27;entropy&#x27;: 0.54818004, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 128.0, &#x27;num_grad_updates_lifetime&#x27;: 4185.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 464.5}}, &#x27;num_env_steps_sampled&#x27;: 20000, &#x27;num_env_steps_trained&#x27;: 20000, &#x27;num_agent_steps_sampled&#x27;: 20000, &#x27;num_agent_steps_trained&#x27;: 20000}</td><td style=\"text-align: right;\">                         5</td><td>127.0.0.1</td><td style=\"text-align: right;\">                    20000</td><td style=\"text-align: right;\">                    20000</td><td style=\"text-align: right;\">                  20000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                  20000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: 28.483333333333334, &#x27;ram_util_percent&#x27;: 71.31666666666668}</td><td style=\"text-align: right;\">23572</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.34509124464907015, &#x27;mean_inference_ms&#x27;: 0.8267897491329514, &#x27;mean_action_processing_ms&#x27;: 0.14310844735188502, &#x27;mean_env_wait_ms&#x27;: 0.04206508927980401, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 500.0, &#x27;episode_reward_min&#x27;: 15.0, &#x27;episode_reward_mean&#x27;: 128.79, &#x27;episode_len_mean&#x27;: 128.79, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 13, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [17.0, 132.0, 27.0, 17.0, 66.0, 30.0, 29.0, 40.0, 57.0, 29.0, 61.0, 28.0, 129.0, 35.0, 50.0, 29.0, 53.0, 27.0, 65.0, 27.0, 28.0, 45.0, 45.0, 50.0, 30.0, 64.0, 17.0, 69.0, 23.0, 37.0, 74.0, 230.0, 117.0, 262.0, 137.0, 27.0, 79.0, 48.0, 139.0, 178.0, 76.0, 65.0, 154.0, 81.0, 134.0, 106.0, 15.0, 89.0, 135.0, 84.0, 69.0, 32.0, 93.0, 50.0, 51.0, 131.0, 43.0, 92.0, 153.0, 100.0, 120.0, 118.0, 130.0, 110.0, 96.0, 98.0, 39.0, 117.0, 65.0, 177.0, 87.0, 255.0, 110.0, 169.0, 270.0, 211.0, 130.0, 123.0, 244.0, 232.0, 182.0, 149.0, 213.0, 303.0, 232.0, 273.0, 281.0, 267.0, 252.0, 500.0, 331.0, 415.0, 345.0, 178.0, 376.0, 228.0, 201.0, 227.0, 236.0, 389.0], &#x27;episode_lengths&#x27;: [17, 132, 27, 17, 66, 30, 29, 40, 57, 29, 61, 28, 129, 35, 50, 29, 53, 27, 65, 27, 28, 45, 45, 50, 30, 64, 17, 69, 23, 37, 74, 230, 117, 262, 137, 27, 79, 48, 139, 178, 76, 65, 154, 81, 134, 106, 15, 89, 135, 84, 69, 32, 93, 50, 51, 131, 43, 92, 153, 100, 120, 118, 130, 110, 96, 98, 39, 117, 65, 177, 87, 255, 110, 169, 270, 211, 130, 123, 244, 232, 182, 149, 213, 303, 232, 273, 281, 267, 252, 500, 331, 415, 345, 178, 376, 228, 201, 227, 236, 389]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.34509124464907015, &#x27;mean_inference_ms&#x27;: 0.8267897491329514, &#x27;mean_action_processing_ms&#x27;: 0.14310844735188502, &#x27;mean_env_wait_ms&#x27;: 0.04206508927980401, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.009012222290039062, &#x27;StateBufferConnector_ms&#x27;: 0.010036945343017578, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.12197756767272949}}</td><td style=\"text-align: right;\">             27.5592</td><td style=\"text-align: right;\">           4.40509</td><td style=\"text-align: right;\">       27.5592</td><td>{&#x27;training_iteration_time_ms&#x27;: 5504.588, &#x27;load_time_ms&#x27;: 0.2, &#x27;load_throughput&#x27;: 20025323.466, &#x27;learn_time_ms&#x27;: 2891.284, &#x27;learn_throughput&#x27;: 1383.468, &#x27;synch_weights_time_ms&#x27;: 3.101}</td><td style=\"text-align: right;\"> 1677598456</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            20000</td><td style=\"text-align: right;\">                   5</td><td>3cf6c_00000</td><td style=\"text-align: right;\">      15.9019</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 16:34:17,436\tINFO tune.py:798 -- Total run time: 53.45 seconds (52.55 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "result = train_rl_ppo_online(num_workers=2, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 9.772552, 'policy_loss': -0.019828321, 'vf_loss': 9.791359, 'vf_explained_var': -0.013446819, 'kl': 0.0033996392, 'entropy': 0.54818004, 'entropy_coeff': 0.0, 'model': {}}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4185.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'sampler_results': {'episode_reward_max': 500.0, 'episode_reward_min': 15.0, 'episode_reward_mean': 128.79, 'episode_len_mean': 128.79, 'episode_media': {}, 'episodes_this_iter': 13, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [17.0, 132.0, 27.0, 17.0, 66.0, 30.0, 29.0, 40.0, 57.0, 29.0, 61.0, 28.0, 129.0, 35.0, 50.0, 29.0, 53.0, 27.0, 65.0, 27.0, 28.0, 45.0, 45.0, 50.0, 30.0, 64.0, 17.0, 69.0, 23.0, 37.0, 74.0, 230.0, 117.0, 262.0, 137.0, 27.0, 79.0, 48.0, 139.0, 178.0, 76.0, 65.0, 154.0, 81.0, 134.0, 106.0, 15.0, 89.0, 135.0, 84.0, 69.0, 32.0, 93.0, 50.0, 51.0, 131.0, 43.0, 92.0, 153.0, 100.0, 120.0, 118.0, 130.0, 110.0, 96.0, 98.0, 39.0, 117.0, 65.0, 177.0, 87.0, 255.0, 110.0, 169.0, 270.0, 211.0, 130.0, 123.0, 244.0, 232.0, 182.0, 149.0, 213.0, 303.0, 232.0, 273.0, 281.0, 267.0, 252.0, 500.0, 331.0, 415.0, 345.0, 178.0, 376.0, 228.0, 201.0, 227.0, 236.0, 389.0], 'episode_lengths': [17, 132, 27, 17, 66, 30, 29, 40, 57, 29, 61, 28, 129, 35, 50, 29, 53, 27, 65, 27, 28, 45, 45, 50, 30, 64, 17, 69, 23, 37, 74, 230, 117, 262, 137, 27, 79, 48, 139, 178, 76, 65, 154, 81, 134, 106, 15, 89, 135, 84, 69, 32, 93, 50, 51, 131, 43, 92, 153, 100, 120, 118, 130, 110, 96, 98, 39, 117, 65, 177, 87, 255, 110, 169, 270, 211, 130, 123, 244, 232, 182, 149, 213, 303, 232, 273, 281, 267, 252, 500, 331, 415, 345, 178, 376, 228, 201, 227, 236, 389]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.34509124464907015, 'mean_inference_ms': 0.8267897491329514, 'mean_action_processing_ms': 0.14310844735188502, 'mean_env_wait_ms': 0.04206508927980401, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009012222290039062, 'StateBufferConnector_ms': 0.010036945343017578, 'ViewRequirementAgentConnector_ms': 0.12197756767272949}}, 'episode_reward_max': 500.0, 'episode_reward_min': 15.0, 'episode_reward_mean': 128.79, 'episode_len_mean': 128.79, 'episodes_this_iter': 13, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [17.0, 132.0, 27.0, 17.0, 66.0, 30.0, 29.0, 40.0, 57.0, 29.0, 61.0, 28.0, 129.0, 35.0, 50.0, 29.0, 53.0, 27.0, 65.0, 27.0, 28.0, 45.0, 45.0, 50.0, 30.0, 64.0, 17.0, 69.0, 23.0, 37.0, 74.0, 230.0, 117.0, 262.0, 137.0, 27.0, 79.0, 48.0, 139.0, 178.0, 76.0, 65.0, 154.0, 81.0, 134.0, 106.0, 15.0, 89.0, 135.0, 84.0, 69.0, 32.0, 93.0, 50.0, 51.0, 131.0, 43.0, 92.0, 153.0, 100.0, 120.0, 118.0, 130.0, 110.0, 96.0, 98.0, 39.0, 117.0, 65.0, 177.0, 87.0, 255.0, 110.0, 169.0, 270.0, 211.0, 130.0, 123.0, 244.0, 232.0, 182.0, 149.0, 213.0, 303.0, 232.0, 273.0, 281.0, 267.0, 252.0, 500.0, 331.0, 415.0, 345.0, 178.0, 376.0, 228.0, 201.0, 227.0, 236.0, 389.0], 'episode_lengths': [17, 132, 27, 17, 66, 30, 29, 40, 57, 29, 61, 28, 129, 35, 50, 29, 53, 27, 65, 27, 28, 45, 45, 50, 30, 64, 17, 69, 23, 37, 74, 230, 117, 262, 137, 27, 79, 48, 139, 178, 76, 65, 154, 81, 134, 106, 15, 89, 135, 84, 69, 32, 93, 50, 51, 131, 43, 92, 153, 100, 120, 118, 130, 110, 96, 98, 39, 117, 65, 177, 87, 255, 110, 169, 270, 211, 130, 123, 244, 232, 182, 149, 213, 303, 232, 273, 281, 267, 252, 500, 331, 415, 345, 178, 376, 228, 201, 227, 236, 389]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.34509124464907015, 'mean_inference_ms': 0.8267897491329514, 'mean_action_processing_ms': 0.14310844735188502, 'mean_env_wait_ms': 0.04206508927980401, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009012222290039062, 'StateBufferConnector_ms': 0.010036945343017578, 'ViewRequirementAgentConnector_ms': 0.12197756767272949}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 5504.588, 'load_time_ms': 0.2, 'load_throughput': 20025323.466, 'learn_time_ms': 2891.284, 'learn_throughput': 1383.468, 'synch_weights_time_ms': 3.101}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'done': True, 'trial_id': '3cf6c_00000', 'perf': {'cpu_util_percent': 28.483333333333334, 'ram_util_percent': 71.31666666666668}, 'experiment_tag': '0'}, error=None, log_dir=WindowsPath('C:/Users/rober/ray_results/AIRPPO_2023-02-28_16-33-13/AIRPPO_3cf6c_00000_0_2023-02-28_16-33-24'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 16:35:49,000\tINFO policy.py:1214 -- Policy (worker=local) running on CPU.\n",
      "2023-02-28 16:35:49,001\tINFO tf_policy.py:171 -- Found 0 visible cuda devices.\n",
      "2023-02-28 16:35:49,171\tINFO dynamic_tf_policy_v2.py:710 -- Adding extra-action-fetch `action_prob` to view-reqs.\n",
      "2023-02-28 16:35:49,172\tINFO dynamic_tf_policy_v2.py:710 -- Adding extra-action-fetch `action_logp` to view-reqs.\n",
      "2023-02-28 16:35:49,173\tINFO dynamic_tf_policy_v2.py:710 -- Adding extra-action-fetch `action_dist_inputs` to view-reqs.\n",
      "2023-02-28 16:35:49,175\tINFO dynamic_tf_policy_v2.py:710 -- Adding extra-action-fetch `vf_preds` to view-reqs.\n",
      "2023-02-28 16:35:49,175\tINFO dynamic_tf_policy_v2.py:722 -- Testing `postprocess_trajectory` w/ dummy batch.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1336\\1440705907.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_eval_episodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_using_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_eval_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Average reward over {num_eval_episodes} episodes: \"\u001b[0m \u001b[1;34mf\"{np.mean(rewards)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1336\\2452460140.py\u001b[0m in \u001b[0;36mevaluate_using_checkpoint\u001b[1;34m(checkpoint, num_episodes)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "num_eval_episodes = 3\n",
    "\n",
    "rewards = evaluate_using_checkpoint(result.checkpoint, num_episodes=num_eval_episodes)\n",
    "print(f\"Average reward over {num_eval_episodes} episodes: \" f\"{np.mean(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b4678716a022edc46aedeb623a5f6581a88ad14901e1955d84adae753a20813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
