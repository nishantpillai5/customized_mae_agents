{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "import os\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "# from ray.rllib.algorithms.apex_ddpg import ApexDDPGConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig, DQNTFPolicy, DQNTorchPolicy\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(render_mode=\"rgb_array\", cycles=200):\n",
    "    from src.world import world_utils\n",
    "    env = world_utils.env(render_mode=render_mode, max_cycles=cycles)\n",
    "    return env\n",
    "\n",
    "register_env(\"tagworld\", lambda config: ParallelPettingZooEnv(env_creator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing non-identical observation spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supersuit import pad_action_space_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/pettingzoo/utils/wrappers/base.py:50: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'adversary_0': Box(-inf, inf, (30,), float32),\n",
       " 'adversary_1': Box(-inf, inf, (30,), float32),\n",
       " 'adversary_2': Box(-inf, inf, (30,), float32),\n",
       " 'agent_0': Box(-inf, inf, (28,), float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space = env.observation_space\n",
    "act_space = env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_iters = 20\n",
    "stop_timesteps = 100000\n",
    "stop_reward = 50.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 18:50:17,817\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.16</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.16', ray_version='2.3.0', ray_commit='cf7a56b4b0b648c324722df7c99c168e92ff0b45', address_info={'node_ip_address': '192.168.10.107', 'raylet_ip_address': '192.168.10.107', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-03-10_18-50-15_077283_216747/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-03-10_18-50-15_077283_216747/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-03-10_18-50-15_077283_216747', 'metrics_export_port': 35057, 'gcs_address': '192.168.10.107:60633', 'address': '192.168.10.107:60633', 'dashboard_agent_listen_port': 52365, 'node_id': 'd173d59615e61f22f4dc99fcad421d71ef696b808d17d04485b8aaa4'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = {\n",
    "    \"dqn_policy\": (\n",
    "    DQNTorchPolicy,\n",
    "    obs_space,\n",
    "    act_space,\n",
    "    {},\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    return \"dqn_policy\"\n",
    "        # if agent_id % 2 == 0:\n",
    "            # return \"ppo_policy\"\n",
    "        # else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 18:50:26,721\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Observation spaces for all agents must be identical. Perhaps SuperSuit's pad_observations wrapper can help (useage: `supersuit.aec_wrappers.pad_observations(env)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m dqn_config \u001b[39m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m         DQNConfig()\n\u001b[1;32m      3\u001b[0m         \u001b[39m.\u001b[39menvironment(\u001b[39m\"\u001b[39m\u001b[39mtagworld\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[39m.\u001b[39mresources(num_gpus\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mRLLIB_NUM_GPUS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m     20\u001b[0m     )\n\u001b[0;32m---> 22\u001b[0m dqn \u001b[39m=\u001b[39m dqn_config\u001b[39m.\u001b[39;49mbuild()\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm_config.py:926\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator, use_copy)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    924\u001b[0m     algo_class \u001b[39m=\u001b[39m get_trainable_cls(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class)\n\u001b[0;32m--> 926\u001b[0m \u001b[39mreturn\u001b[39;00m algo_class(\n\u001b[1;32m    927\u001b[0m     config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m use_copy \u001b[39melse\u001b[39;49;00m copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m),\n\u001b[1;32m    928\u001b[0m     logger_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger_creator,\n\u001b[1;32m    929\u001b[0m )\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:445\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_metrics \u001b[39m=\u001b[39m {\n\u001b[1;32m    438\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mevaluation\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mepisode_reward_max\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     }\n\u001b[1;32m    443\u001b[0m }\n\u001b[0;32m--> 445\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    446\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    447\u001b[0m     logger_creator\u001b[39m=\u001b[39;49mlogger_creator,\n\u001b[1;32m    448\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    451\u001b[0m \u001b[39m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/tune/trainable/trainable.py:169\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_ip \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mget_node_ip_address()\n\u001b[0;32m--> 169\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig))\n\u001b[1;32m    170\u001b[0m setup_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m setup_time \u001b[39m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:571\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mif\u001b[39;00m _init \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m     \u001b[39m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     \u001b[39m#   in each training iteration.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[39m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[39m# has been deprecated.\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers \u001b[39m=\u001b[39m WorkerSet(\n\u001b[1;32m    572\u001b[0m         env_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv_creator,\n\u001b[1;32m    573\u001b[0m         validate_env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_env,\n\u001b[1;32m    574\u001b[0m         default_policy_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_default_policy_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig),\n\u001b[1;32m    575\u001b[0m         config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig,\n\u001b[1;32m    576\u001b[0m         num_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_rollout_workers,\n\u001b[1;32m    577\u001b[0m         local_worker\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    578\u001b[0m         logdir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogdir,\n\u001b[1;32m    579\u001b[0m     )\n\u001b[1;32m    581\u001b[0m     \u001b[39m# TODO (avnishn): Remove the execution plan API by q1 2023\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[39m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_disable_execution_plan_api:\n\u001b[1;32m    584\u001b[0m         \u001b[39m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:170\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m _setup:\n\u001b[1;32m    169\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup(\n\u001b[1;32m    171\u001b[0m             validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m    172\u001b[0m             config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    173\u001b[0m             num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    174\u001b[0m             local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m     \u001b[39m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[39m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[39m# constructor).\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[39mexcept\u001b[39;00m RayActorError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m         \u001b[39m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         \u001b[39m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[39m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m         \u001b[39m# errors.\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:260\u001b[0m, in \u001b[0;36mWorkerSet._setup\u001b[0;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39m# Create a local worker, if needed.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m local_worker:\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_worker \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_worker(\n\u001b[1;32m    261\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49mRolloutWorker,\n\u001b[1;32m    262\u001b[0m         env_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_env_creator,\n\u001b[1;32m    263\u001b[0m         validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m    264\u001b[0m         worker_index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m    265\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    266\u001b[0m         config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_local_config,\n\u001b[1;32m    267\u001b[0m         spaces\u001b[39m=\u001b[39;49mspaces,\n\u001b[1;32m    268\u001b[0m     )\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:946\u001b[0m, in \u001b[0;36mWorkerSet._make_worker\u001b[0;34m(self, cls, env_creator, validate_env, worker_index, num_workers, recreated_worker, config, spaces)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_worker\u001b[39m(\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    934\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     ] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    945\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[RolloutWorker, ActorHandle]:\n\u001b[0;32m--> 946\u001b[0m     worker \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    947\u001b[0m         env_creator\u001b[39m=\u001b[39;49menv_creator,\n\u001b[1;32m    948\u001b[0m         validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m    949\u001b[0m         default_policy_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_policy_class,\n\u001b[1;32m    950\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    951\u001b[0m         worker_index\u001b[39m=\u001b[39;49mworker_index,\n\u001b[1;32m    952\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    953\u001b[0m         recreated_worker\u001b[39m=\u001b[39;49mrecreated_worker,\n\u001b[1;32m    954\u001b[0m         log_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_logdir,\n\u001b[1;32m    955\u001b[0m         spaces\u001b[39m=\u001b[39;49mspaces,\n\u001b[1;32m    956\u001b[0m         dataset_shards\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ds_shards,\n\u001b[1;32m    957\u001b[0m     )\n\u001b[1;32m    959\u001b[0m     \u001b[39mreturn\u001b[39;00m worker\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py:607\u001b[0m, in \u001b[0;36mRolloutWorker.__init__\u001b[0;34m(self, env_creator, validate_env, config, worker_index, num_workers, recreated_worker, log_dir, spaces, default_policy_class, dataset_shards, policy_config, input_creator, output_creator, rollout_fragment_length, count_steps_by, batch_mode, episode_horizon, preprocessor_pref, sample_async, compress_observations, num_envs, observation_fn, clip_rewards, normalize_actions, clip_actions, env_config, model_config, remote_worker_envs, remote_env_batch_wait_ms, soft_horizon, no_done_at_end, fake_sampler, seed, log_level, callbacks, disable_env_checking, policy_spec, policy_mapping_fn, policies_to_train, extra_python_environs, policy, tf_session_creator)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39m# Create a (single) env for this worker.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    602\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworker_index \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    603\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    604\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcreate_env_on_local_worker\n\u001b[1;32m    605\u001b[0m ):\n\u001b[1;32m    606\u001b[0m     \u001b[39m# Run the `env_creator` function passing the EnvContext.\u001b[39;00m\n\u001b[0;32m--> 607\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m env_creator(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv_context))\n\u001b[1;32m    609\u001b[0m clip_rewards \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mclip_rewards\n\u001b[1;32m    611\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     \u001b[39m# Validate environment (general validation function).\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[39m=\u001b[39m env_creator()\n\u001b[1;32m      2\u001b[0m env \u001b[39m=\u001b[39m pad_action_space_v0(env)\n\u001b[0;32m----> 3\u001b[0m register_env(\u001b[39m\"\u001b[39m\u001b[39mtagworld\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlambda\u001b[39;00m config: ParallelPettingZooEnv(env_creator(config)))\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py:184\u001b[0m, in \u001b[0;36mParallelPettingZooEnv.__init__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39m# Get first action space, assuming all agents have equal space\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpar_env\u001b[39m.\u001b[39maction_space(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpar_env\u001b[39m.\u001b[39magents[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 184\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    185\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpar_env\u001b[39m.\u001b[39mobservation_space(agent) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space\n\u001b[1;32m    186\u001b[0m     \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpar_env\u001b[39m.\u001b[39magents\n\u001b[1;32m    187\u001b[0m ), (\n\u001b[1;32m    188\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mObservation spaces for all agents must be identical. Perhaps \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSuperSuit\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms pad_observations wrapper can help (useage: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`supersuit.aec_wrappers.pad_observations(env)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpar_env\u001b[39m.\u001b[39maction_space(agent) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\n\u001b[1;32m    195\u001b[0m     \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpar_env\u001b[39m.\u001b[39magents\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`supersuit.aec_wrappers.pad_action_space(env)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Observation spaces for all agents must be identical. Perhaps SuperSuit's pad_observations wrapper can help (useage: `supersuit.aec_wrappers.pad_observations(env)`"
     ]
    }
   ],
   "source": [
    "dqn_config = (\n",
    "        DQNConfig()\n",
    "        .environment(\"tagworld\")\n",
    "        .framework(\"torch\")\n",
    "        # disable filters, otherwise we would need to synchronize those\n",
    "        # as well to the DQN agent\n",
    "        .rollouts(observation_filter=\"MeanStdFilter\")\n",
    "        .training(\n",
    "            model={\"vf_share_layers\": True},\n",
    "            n_step=3,\n",
    "            gamma=0.95,\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            policy_mapping_fn=policy_mapping_fn,\n",
    "            policies_to_train=[\"dqn_policy\"],\n",
    "        )\n",
    "        # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "        .resources(num_gpus=int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")))\n",
    "    )\n",
    "\n",
    "dqn = dqn_config.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(stop_iters):\n",
    "    print(\"== Iteration\", i, \"==\")\n",
    "\n",
    "    # improve the DQN policy\n",
    "    print(\"-- DQN --\")\n",
    "    result_dqn = dqn.train()\n",
    "    print(pretty_print(result_dqn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b4678716a022edc46aedeb623a5f6581a88ad14901e1955d84adae753a20813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
