{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "# from ray.rllib.algorithms.apex_ddpg import ApexDDPGConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig, DQNTFPolicy, DQNTorchPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(render_mode=\"rgb_array\", cycles=200):\n",
    "    from src.world import world_utils\n",
    "    env = world_utils.env(render_mode=render_mode, max_cycles=cycles)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_iters = 20\n",
    "stop_timesteps = 100000\n",
    "stop_reward = 50.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 16:59:29,790\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "env = env_creator()\n",
    "register_env(\"tagworld\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space = env.observation_space\n",
    "act_space = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = {\n",
    "    \"dqn_policy\": (\n",
    "    DQNTorchPolicy,\n",
    "    obs_space,\n",
    "    act_space,\n",
    "    {},\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    return \"dqn_policy\"\n",
    "        # if agent_id % 2 == 0:\n",
    "            # return \"ppo_policy\"\n",
    "        # else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 17:01:28,217\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n    raise ValueError(\nValueError: Env must be of one of the following supported types: BaseEnv, gymnasium.Env, gym.Env, MultiAgentEnv, VectorEnv, RemoteBaseEnv, ExternalMultiAgentEnv, ExternalEnv, but instead is of type <class 'pettingzoo.utils.wrappers.order_enforcing.OrderEnforcingWrapper'>.\n\nThe above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior via calling `config.environment(disable_env_checking=True)`. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([your env]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py:70\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m     58\u001b[0m     env,\n\u001b[1;32m     59\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     ),\n\u001b[1;32m     69\u001b[0m ) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m old_gym \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(env, old_gym\u001b[39m.\u001b[39mEnv)):\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEnv must be of one of the following supported types: BaseEnv, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgymnasium.Env, gym.Env, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMultiAgentEnv, VectorEnv, RemoteBaseEnv, ExternalMultiAgentEnv, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExternalEnv, but instead is of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(env)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(env, MultiAgentEnv):\n",
      "\u001b[0;31mValueError\u001b[0m: Env must be of one of the following supported types: BaseEnv, gymnasium.Env, gym.Env, MultiAgentEnv, VectorEnv, RemoteBaseEnv, ExternalMultiAgentEnv, ExternalEnv, but instead is of type <class 'pettingzoo.utils.wrappers.order_enforcing.OrderEnforcingWrapper'>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m dqn_config \u001b[39m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m         DQNConfig()\n\u001b[1;32m      3\u001b[0m         \u001b[39m.\u001b[39menvironment(\u001b[39m\"\u001b[39m\u001b[39mtagworld\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[39m.\u001b[39mresources(num_gpus\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mRLLIB_NUM_GPUS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m     20\u001b[0m     )\n\u001b[0;32m---> 22\u001b[0m dqn \u001b[39m=\u001b[39m dqn_config\u001b[39m.\u001b[39;49mbuild()\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm_config.py:926\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator, use_copy)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    924\u001b[0m     algo_class \u001b[39m=\u001b[39m get_trainable_cls(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class)\n\u001b[0;32m--> 926\u001b[0m \u001b[39mreturn\u001b[39;00m algo_class(\n\u001b[1;32m    927\u001b[0m     config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m use_copy \u001b[39melse\u001b[39;49;00m copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m),\n\u001b[1;32m    928\u001b[0m     logger_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger_creator,\n\u001b[1;32m    929\u001b[0m )\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:445\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_metrics \u001b[39m=\u001b[39m {\n\u001b[1;32m    438\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mevaluation\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mepisode_reward_max\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     }\n\u001b[1;32m    443\u001b[0m }\n\u001b[0;32m--> 445\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    446\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    447\u001b[0m     logger_creator\u001b[39m=\u001b[39;49mlogger_creator,\n\u001b[1;32m    448\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    451\u001b[0m \u001b[39m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/tune/trainable/trainable.py:169\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_ip \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mget_node_ip_address()\n\u001b[0;32m--> 169\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig))\n\u001b[1;32m    170\u001b[0m setup_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m setup_time \u001b[39m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:571\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mif\u001b[39;00m _init \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m     \u001b[39m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     \u001b[39m#   in each training iteration.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[39m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[39m# has been deprecated.\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers \u001b[39m=\u001b[39m WorkerSet(\n\u001b[1;32m    572\u001b[0m         env_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv_creator,\n\u001b[1;32m    573\u001b[0m         validate_env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_env,\n\u001b[1;32m    574\u001b[0m         default_policy_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_default_policy_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig),\n\u001b[1;32m    575\u001b[0m         config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig,\n\u001b[1;32m    576\u001b[0m         num_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_rollout_workers,\n\u001b[1;32m    577\u001b[0m         local_worker\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    578\u001b[0m         logdir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogdir,\n\u001b[1;32m    579\u001b[0m     )\n\u001b[1;32m    581\u001b[0m     \u001b[39m# TODO (avnishn): Remove the execution plan API by q1 2023\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[39m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_disable_execution_plan_api:\n\u001b[1;32m    584\u001b[0m         \u001b[39m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:170\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m _setup:\n\u001b[1;32m    169\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup(\n\u001b[1;32m    171\u001b[0m             validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m    172\u001b[0m             config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    173\u001b[0m             num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    174\u001b[0m             local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m     \u001b[39m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[39m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[39m# constructor).\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[39mexcept\u001b[39;00m RayActorError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m         \u001b[39m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         \u001b[39m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[39m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m         \u001b[39m# errors.\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:260\u001b[0m, in \u001b[0;36mWorkerSet._setup\u001b[0;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39m# Create a local worker, if needed.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m local_worker:\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_worker \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_worker(\n\u001b[1;32m    261\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49mRolloutWorker,\n\u001b[1;32m    262\u001b[0m         env_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_env_creator,\n\u001b[1;32m    263\u001b[0m         validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m    264\u001b[0m         worker_index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m    265\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    266\u001b[0m         config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_local_config,\n\u001b[1;32m    267\u001b[0m         spaces\u001b[39m=\u001b[39;49mspaces,\n\u001b[1;32m    268\u001b[0m     )\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:946\u001b[0m, in \u001b[0;36mWorkerSet._make_worker\u001b[0;34m(self, cls, env_creator, validate_env, worker_index, num_workers, recreated_worker, config, spaces)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_worker\u001b[39m(\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    934\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     ] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    945\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[RolloutWorker, ActorHandle]:\n\u001b[0;32m--> 946\u001b[0m     worker \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    947\u001b[0m         env_creator\u001b[39m=\u001b[39;49menv_creator,\n\u001b[1;32m    948\u001b[0m         validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m    949\u001b[0m         default_policy_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_policy_class,\n\u001b[1;32m    950\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    951\u001b[0m         worker_index\u001b[39m=\u001b[39;49mworker_index,\n\u001b[1;32m    952\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    953\u001b[0m         recreated_worker\u001b[39m=\u001b[39;49mrecreated_worker,\n\u001b[1;32m    954\u001b[0m         log_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_logdir,\n\u001b[1;32m    955\u001b[0m         spaces\u001b[39m=\u001b[39;49mspaces,\n\u001b[1;32m    956\u001b[0m         dataset_shards\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ds_shards,\n\u001b[1;32m    957\u001b[0m     )\n\u001b[1;32m    959\u001b[0m     \u001b[39mreturn\u001b[39;00m worker\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py:614\u001b[0m, in \u001b[0;36mRolloutWorker.__init__\u001b[0;34m(self, env_creator, validate_env, config, worker_index, num_workers, recreated_worker, log_dir, spaces, default_policy_class, dataset_shards, policy_config, input_creator, output_creator, rollout_fragment_length, count_steps_by, batch_mode, episode_horizon, preprocessor_pref, sample_async, compress_observations, num_envs, observation_fn, clip_rewards, normalize_actions, clip_actions, env_config, model_config, remote_worker_envs, remote_env_batch_wait_ms, soft_horizon, no_done_at_end, fake_sampler, seed, log_level, callbacks, disable_env_checking, policy_spec, policy_mapping_fn, policies_to_train, extra_python_environs, policy, tf_session_creator)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     \u001b[39m# Validate environment (general validation function).\u001b[39;00m\n\u001b[1;32m    613\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdisable_env_checking:\n\u001b[0;32m--> 614\u001b[0m         check_env(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv)\n\u001b[1;32m    615\u001b[0m     \u001b[39m# Custom validation function given, typically a function attribute of the\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     \u001b[39m# algorithm trainer.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m     \u001b[39mif\u001b[39;00m validate_env \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py:93\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     actual_error \u001b[39m=\u001b[39m traceback\u001b[39m.\u001b[39mformat_exc()\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mactual_error\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe above error has been found in your environment! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWe\u001b[39m\u001b[39m'\u001b[39m\u001b[39mve added a module for checking your custom environments. It \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmay cause your experiment to fail if your environment is not set up \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorrectly. You can disable this behavior via calling `config.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39menvironment(disable_env_checking=True)`. You can run the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39menvironment checking module standalone by calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mray.rllib.utils.check_env([your env]).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"/run/media/nishant/Data/Work/uni/thesis/repo/env/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n    raise ValueError(\nValueError: Env must be of one of the following supported types: BaseEnv, gymnasium.Env, gym.Env, MultiAgentEnv, VectorEnv, RemoteBaseEnv, ExternalMultiAgentEnv, ExternalEnv, but instead is of type <class 'pettingzoo.utils.wrappers.order_enforcing.OrderEnforcingWrapper'>.\n\nThe above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior via calling `config.environment(disable_env_checking=True)`. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([your env])."
     ]
    }
   ],
   "source": [
    "dqn_config = (\n",
    "        DQNConfig()\n",
    "        .environment(\"tagworld\")\n",
    "        .framework(\"torch\")\n",
    "        # disable filters, otherwise we would need to synchronize those\n",
    "        # as well to the DQN agent\n",
    "        .rollouts(observation_filter=\"MeanStdFilter\")\n",
    "        .training(\n",
    "            model={\"vf_share_layers\": True},\n",
    "            n_step=3,\n",
    "            gamma=0.95,\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            policy_mapping_fn=policy_mapping_fn,\n",
    "            policies_to_train=[\"dqn_policy\"],\n",
    "        )\n",
    "        # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "        .resources(num_gpus=int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")))\n",
    "    )\n",
    "\n",
    "dqn = dqn_config.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(stop_iters):\n",
    "    print(\"== Iteration\", i, \"==\")\n",
    "\n",
    "    # improve the DQN policy\n",
    "    print(\"-- DQN --\")\n",
    "    result_dqn = dqn.train()\n",
    "    print(pretty_print(result_dqn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b4678716a022edc46aedeb623a5f6581a88ad14901e1955d84adae753a20813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
